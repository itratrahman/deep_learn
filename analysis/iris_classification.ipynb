{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS DATA CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains neural network to classify iris data. The training manifesto given in the notebook follows the caviar search strategy for hyperparameter tuning, a technique is followed by machine learning scientists and engineers for training deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import deep_learn package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from deep_learn.nn import ann\n",
    "except:\n",
    "    from config import *\n",
    "    append_path('../')\n",
    "    from deep_learn.nn import ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import neccessary package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and reshape data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load iris data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store the data in pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the X y data horizontally\n",
    "data = np.hstack((X,y))\n",
    "# store the numpy array in pandas dataframe\n",
    "data = pd.DataFrame(data=data, columns=iris.feature_names +['species'])\n",
    "# shuffle the data\n",
    "data = data.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features and output of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.feature_names\n",
    "output = 'species'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do a train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size = 0.266, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to extract feature matrix and output vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_data(dataframe, features = None, output = None):\n",
    "\n",
    "    '''a function for parsing the feature matrix and output array from a pandas dataframe'''\n",
    "\n",
    "    # to ignore pandas warning\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # import numpy\n",
    "    import numpy as np\n",
    "\n",
    "    # if no featues are given then just return the a numpy matrix of the dataframe\n",
    "    if features == None:\n",
    "        return dataframe.as_matrix()\n",
    "\n",
    "    # extract the feature matrix and convert it to numpy array\n",
    "    X = dataframe[features].as_matrix()\n",
    "\n",
    "    # if there is no output\n",
    "    if output == None:\n",
    "        return X\n",
    "    # if the output vector is wanted by the user\n",
    "    else:\n",
    "        # extracting the output columns and converting it to numpy array\n",
    "        y = dataframe[output].as_matrix()\n",
    "        y = np.reshape(y, (-1,1))\n",
    "        # returning the feature matrix and output vector\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract X y data for train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_xy_data(train_data, features=features, output=output)\n",
    "X_test, Y_test = get_xy_data(test_data, features=features, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Onehot encoding the y data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_train = Y_train.toarray()\n",
    "Y_test = encoder.transform(Y_test)\n",
    "Y_test = Y_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the first neural network for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of first neural network is a dirty implementation which allows engineers to test if the network along with its hyperparameters, architecture, loss function actually works. After creating dirty implementation engineers do hyperparameter tuning. Now the iris dataset for is a very simple data to create a very accurate first implementation. Things will not so easy for example creating a yolo object detection network for detecting vehicles, pedestrians, and road signs for self driving system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [4,4,8,8,4,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a nn model object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ann(layers_dims=layers_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X_train.shape[0]\n",
    "learning_rate = 0.1*.5\n",
    "num_iterations = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, X_test, Y_test, batch_size,\n",
    "          learning_rate = learning_rate, \n",
    "          num_iterations = num_iterations, print_cost=True, random_seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of Cost vs Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost\n",
    "plt.plot(np.squeeze(model.costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Caviar Strategy for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 strategies for deep learning hyperparamter tuning: 1) Panda strategy in which we babysit a single model, this is applicable if computing resource is limited 2) Caviar strategy in which we randomly initialize a number of hyperparameter settings and train neural network model using different settings and then choose the one with the lowest error, this is strategy is applicable if we have enormous computing resource. In this notebook I will choose to tune the parameters of learning rate and nn architecture using caviar strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to generate a given number of nn architectures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_and_node_generator(model_num, num_input, num_output, randome_seed = 0, low = 8, high=17):\n",
    "    \n",
    "    '''a function to generate a given number of nn architectures'''\n",
    "    \n",
    "    # set the random seed\n",
    "    np.random.seed(randome_seed)\n",
    "    \n",
    "    # list to store the architectures\n",
    "    model_architecture_list = []\n",
    "    \n",
    "    # iterate given number of times\n",
    "    for i in range(model_num):\n",
    "        # randomly generate number of hidden layers\n",
    "        num_hidden = np.random.randint(low = 3, high = 6)\n",
    "        # randomly generate the number of nodes in each layer\n",
    "        layers_dims = np.random.randint(low = low, high = high, size = num_hidden)\n",
    "        layers_dims = layers_dims.tolist()\n",
    "        # insert the input and output layer\n",
    "        layers_dims.insert(0,num_input)\n",
    "        layers_dims.append(num_output)\n",
    "        # append the architecture to the designated list\n",
    "        model_architecture_list.append(layers_dims)\n",
    "    \n",
    "    return model_architecture_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generaty a list of learning rates to choose from**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.round(np.linspace(0.1*0.5,0.1*5,num=200),4)\n",
    "learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to randomly generate a given number of learning rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_generator(learning_rates, model_num, randome_seed = 0):\n",
    "    \n",
    "    '''a function to randomly generate a given number of learning rates'''\n",
    "    \n",
    "    np.random.seed(randome_seed)\n",
    "    \n",
    "    return np.random.choice(learning_rates, size=model_num).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function which implements a caviar strategy search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caviar_strategy_search(model_num, batch_size, randome_seed = 0, num_iterations = 40000):\n",
    "    \n",
    "    '''a function which implements a caviar strategy search'''\n",
    "    \n",
    "    # randomly generate a list of learning rates\n",
    "    learning_rate_list = learning_rate_generator(learning_rates, model_num, randome_seed = randome_seed)\n",
    "    # randomly generate a list of architectures \n",
    "    model_architecture_list = hidden_layer_and_node_generator(model_num,4,3, randome_seed = randome_seed)\n",
    "    # lists to store the costs and accuracy of models\n",
    "    cost_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    # iterate a given number of times\n",
    "    for i in range(model_num):\n",
    "        # create and fit a nn model with given architecture\n",
    "        model = ann(layers_dims=model_architecture_list[i])\n",
    "        model.fit(X_train, Y_train, X_test, Y_test, batch_size,\n",
    "                  learning_rate = learning_rate_list[i], \n",
    "                  num_iterations = num_iterations, print_cost=False, random_seed = randome_seed)\n",
    "        # append the average of last 5 costs to the designated list\n",
    "        cost_list.append(np.average(model.costs[-5:]))\n",
    "        # append the accuracy to the designated list\n",
    "        accuracy_list.append(model.accuracy)\n",
    "        # print statement\n",
    "        print(\"Completed training and collected results for the model:\",str(i+1))\n",
    "        \n",
    "    return model_architecture_list, learning_rate_list, cost_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 20\n",
    "batch_size = X_train.shape[0]\n",
    "randome_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture_list, learning_rate_list, cost_list, accuracy_list = \\\n",
    "caviar_strategy_search(model_num, batch_size, randome_seed = randome_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"model layers\": model_architecture_list,\n",
    "                        \"learning rate\": learning_rate_list,\n",
    "                        \"accuracy\": accuracy_list,\n",
    "                        \"cost\": cost_list})\n",
    "results = results.reindex(columns=[\"model layers\", \"learning rate\", \"accuracy\", \"cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
